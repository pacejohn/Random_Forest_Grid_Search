{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The original file from UCI named adult.test has 16,281 records\n",
    "# https://archive.ics.uci.edu/ml/datasets/Census+Income\n",
    "# Renamed adult.test to adult_data_small...\n",
    "# Changed all categorical fields with text to categorical with integers\n",
    "# Manually split this file into 2 files.  One for train/test and one for validation\n",
    "# adult_data_small_train_test has 14,500 records\n",
    "# adult_data small_val has 1,781 records\n",
    "\n",
    "\n",
    "# The original file from UCI named adult.data has 32,561 records\n",
    "# https://archive.ics.uci.edu/ml/datasets/Census+Income\n",
    "# Renamed adult.data to adult_data_large...\n",
    "# Changed all categorical fields with text to categorical with integers\n",
    "# Manually split this file into 2 files.  One for train/test and one for validation\n",
    "# adult_data_large_train_test has 29,000 records\n",
    "# adult_data_large_val has 3,561 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of df created from adult_data_small_train_test.csv is (14500, 15)\n",
      "Shape of df created from adult_data_small_val.csv is (1781, 15)\n",
      "\n",
      "Shape of train-test df after dropping rows with ? is (13424, 15)\n",
      "Shape of val df after dropping rows with ? is (1636, 15)\n"
     ]
    }
   ],
   "source": [
    "# Reading and prepping csv input files\n",
    "# Set input file names\n",
    "train_test_file_name = \"adult_data_small_train_test.csv\"\n",
    "val_file_name = \"adult_data_small_val.csv\"\n",
    "\n",
    "\n",
    "# Read the input files (train/test and validation) into dataframes and add the column names\n",
    "colnames=[\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\", \"marital-status\", \"occupation\", \n",
    "\"relationship\", \"race\", \"sex\", \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\", \"income\"] \n",
    "train_test_df = pd.read_csv(train_test_file_name, names=colnames, header=None) \n",
    "val_df = pd.read_csv(val_file_name, names=colnames, header=None) \n",
    "\n",
    "# View shape of dataframes that were created to make sure they are correct\n",
    "print(\"\\nShape of df created from \" + train_test_file_name + \" is \" + str(train_test_df.shape))\n",
    "print(\"Shape of df created from \" + val_file_name + \" is \" + str(val_df.shape))\n",
    "\n",
    "# Drop any rows that have a ? in a field since values can't be imputed\n",
    "indexNames = train_test_df[(train_test_df[\"workclass\"] == \"?\") | (train_test_df[\"native-country\"] == \"?\") | \n",
    "(train_test_df[\"occupation\"] == \"?\")].index\n",
    "train_test_df.drop(indexNames , inplace=True)\n",
    "\n",
    "indexNames = val_df[(val_df[\"workclass\"] == \"?\") | (val_df[\"native-country\"] == \"?\") | (val_df[\"occupation\"] == \"?\")].index\n",
    "val_df.drop(indexNames , inplace=True)\n",
    "\n",
    "# Reset the indices\n",
    "train_test_df.reset_index(drop=True, inplace=True)\n",
    "val_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# View shape of dataframes after the rows with ? were removed\n",
    "print(\"\\nShape of train-test df after dropping rows with ? is \" + str(train_test_df.shape))\n",
    "print(\"Shape of val df after dropping rows with ? is \" + str(val_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X_train shape = (10739, 14) y_train shape  = (10739,)\n",
      "X_test shape = (2685, 14) y_test shape  = (2685,)\n"
     ]
    }
   ],
   "source": [
    "# Do train/test split for the train_test_df\n",
    "# Get the columns that are needed for the train_test_df_data dataframe\n",
    "cols = [col for col in train_test_df.columns if col not in ['income']]\n",
    "train_test_df_data = train_test_df[cols]\n",
    "train_test_df_target = train_test_df['income']\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_test_df_data, train_test_df_target, test_size=0.2)\n",
    "\n",
    "# View shape of test and train dataframes\n",
    "print(\"\\nX_train shape = \" + str(X_train.shape) + \" y_train shape  = \" + str(y_train.shape))\n",
    "print(\"X_test shape = \" + str(X_test.shape) + \" y_test shape  = \" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***************************************************************\n",
      "*****Random Forest With Default Hyperparameters Train/Test*****\n",
      "***************************************************************\n",
      "\n",
      "*****Default Hyperparameters Test Predictions*****\n",
      "Prediction 1 is 1 with probabilities of [0.2 0.8]\n",
      "Prediction 2 is 1 with probabilities of [0.2 0.8]\n",
      "Prediction 3 is 1 with probabilities of [0. 1.]\n",
      "Prediction 4 is 1 with probabilities of [0.2 0.8]\n",
      "Prediction 5 is 0 with probabilities of [0.9 0.1]\n",
      "\n",
      "*****Default Hyperparameters Test Confusion Matrix*****\n",
      "Predicted Income    0     1\n",
      "Actual Income              \n",
      "0                 437   249\n",
      "1                 209  1790\n",
      "\n",
      "Default Hyperparameters Test Accuracy = 82.9423%\n"
     ]
    }
   ],
   "source": [
    "# ************ Train/Test *********************\n",
    "print(\"\\n***************************************************************\")\n",
    "print(\"*****Random Forest With Default Hyperparameters Train/Test*****\")\n",
    "print(\"***************************************************************\\n\")\n",
    "\n",
    "# ************ Train/Test *********************\n",
    "# Create Random Forest Classifier using default hyperparameters\n",
    "default_rf_clf = RandomForestClassifier(random_state=0)\n",
    "\n",
    "# Train the Classifier\n",
    "default_rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Perform predictions\n",
    "default_train_test_preds = default_rf_clf.predict(X_test)\n",
    "\n",
    "# View the first 5 predictions and the predicted probabilities \n",
    "print(\"*****Default Hyperparameters Test Predictions*****\")\n",
    "for i in range(0,5):\n",
    "\tprint(\"Prediction \" + str(i+1) + \" is \" + str(default_train_test_preds[i]) + \" with probabilities of \" \n",
    "\t\t+ str(default_rf_clf.predict_proba(X_test)[i]))\n",
    "\n",
    "# Create confusion matrix\n",
    "print(\"\\n*****Default Hyperparameters Test Confusion Matrix*****\")\n",
    "confusion_matrix = pd.crosstab(y_test, default_train_test_preds, rownames=['Actual Income'], colnames=['Predicted Income'])\n",
    "print(confusion_matrix)\n",
    "\n",
    "# Print accuracy\n",
    "accuracy = (((confusion_matrix[0][0] + confusion_matrix[1][1])) / (X_test.shape[0]) * 100)\n",
    "print(\"\\nDefault Hyperparameters Test Accuracy = {0:0.4f}%\".format(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "***************************************************************\n",
      "*****Random Forest With Default Hyperparameters Validation*****\n",
      "***************************************************************\n",
      "\n",
      "*****Default Hyperparameters Validation Predictions*****\n",
      "Prediction 1 is 1 with probabilities of [0. 1.]\n",
      "Prediction 2 is 1 with probabilities of [0. 1.]\n",
      "Prediction 3 is 1 with probabilities of [0.2 0.8]\n",
      "Prediction 4 is 1 with probabilities of [0.4 0.6]\n",
      "Prediction 5 is 1 with probabilities of [0. 1.]\n",
      "*****Default Hyperparameters Validation Confusion Matrix*****\n",
      "Predicted Income    0     1\n",
      "Actual Income              \n",
      "0                 252   130\n",
      "1                 119  1135\n",
      "\n",
      "Default Hyperparameters Validation Accuracy = 84.7800%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ************ Validation *********************\n",
    "print(\"\\n\\n***************************************************************\")\n",
    "print(\"*****Random Forest With Default Hyperparameters Validation*****\")\n",
    "print(\"***************************************************************\\n\")\n",
    "\n",
    "\n",
    "# Apply the classifier we trained (default_rf_clf) to the validation data\n",
    "cols = [col for col in val_df.columns if col not in ['income']]\n",
    "val_df_data = val_df[cols]\n",
    "val_df_target = val_df['income']\n",
    "val_preds = default_rf_clf.predict(val_df_data)\n",
    "\n",
    "# View the first 5 predictions and the predicted probabilities \n",
    "print(\"*****Default Hyperparameters Validation Predictions*****\")\n",
    "for i in range(0,5):\n",
    "\tprint(\"Prediction \" + str(i + 1) + \" is \" + str(val_preds[i]) + \" with probabilities of \" \n",
    "\t\t+ str(default_rf_clf.predict_proba(val_df_data)[i]))\n",
    "\n",
    "# Create confusion matrix\n",
    "print(\"*****Default Hyperparameters Validation Confusion Matrix*****\")\n",
    "confusion_matrix = pd.crosstab(val_df_target, val_preds, rownames=['Actual Income'], colnames=['Predicted Income'])\n",
    "print(confusion_matrix)\n",
    "\n",
    "# Print accuracy\n",
    "default_accuracy = (((confusion_matrix[0][0] + confusion_matrix[1][1])) / (val_df_data.shape[0]) * 100)\n",
    "print(\"\\nDefault Hyperparameters Validation Accuracy = {0:0.4f}%\\n\\n\".format(default_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "***************************************************************\n",
      "*****************Random Forest Grid Search*********************\n",
      "***************************************************************\n",
      "\n",
      "The values that will be used for the grid search are:\n",
      "{'bootstrap': [True, False],\n",
      " 'max_depth': [10, 110, None],\n",
      " 'max_features': ['auto', 'sqrt'],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'min_samples_split': [2, 5, 10],\n",
      " 'n_estimators': [200, 2000]}\n",
      "\n",
      "*****Performing the Grid Search of the Hyperparameters*****\n",
      "Fitting 3 folds for each of 216 candidates, totalling 648 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done 290 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 648 out of 648 | elapsed:  3.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best hyperparameters found during the grid search are:\n",
      "{'bootstrap': False,\n",
      " 'max_depth': 10,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 5,\n",
      " 'n_estimators': 2000}\n"
     ]
    }
   ],
   "source": [
    "# ************ Random Forest Classifier using grid search for hyper-parameters ******************\n",
    "print(\"\\n\\n***************************************************************\")\n",
    "print(\"*****************Random Forest Grid Search*********************\")\n",
    "print(\"***************************************************************\\n\")\n",
    "\n",
    "# Number of trees in random forest\n",
    "# Using num=2 will significantly reduce run time (~3 min vs ~65 min)\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 2)]\n",
    "# Using num=10 will significantly increase run time\n",
    "#n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "# Using num=2 will significantly reduce run time (~3 min vs ~65 min)\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 2)]\n",
    "# Using num=10 will significantly increase run time\n",
    "#max_depth = [int(x) for x in np.linspace(10, 110, num = 10)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(\"The values that will be used for the grid search are:\")\n",
    "pprint(grid)\n",
    "\n",
    "print(\"\\n*****Performing the Grid Search of the Hyperparameters*****\")\n",
    "# Create a regressor using values from grid\n",
    "rf_reg = RandomForestRegressor()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf_reg, param_grid = grid, cv = 3, n_jobs = -1, verbose = 1)\n",
    "\n",
    "# Train the classifier\n",
    "best_grid = grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "grid_preds = best_grid.predict(X_test)\n",
    "\n",
    "print(\"The best hyperparameters found during the grid search are:\")\n",
    "pprint(best_grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************************************************************************\n",
      "*****Random Forest With Hyperparameters from Grid Search Train/Test*****\n",
      "************************************************************************\n",
      "\n",
      "\n",
      "\n",
      "*****Grid Search Hyperparameters Test Predictions*****\n",
      "Prediction 1 is 1 with probabilities of [0.20075775 0.79924225]\n",
      "Prediction 2 is 1 with probabilities of [0.08290475 0.91709525]\n",
      "Prediction 3 is 1 with probabilities of [0.00358695 0.99641305]\n",
      "Prediction 4 is 1 with probabilities of [0.28043365 0.71956635]\n",
      "Prediction 5 is 0 with probabilities of [0.96604775 0.03395225]\n",
      "\n",
      "*****Grid Search Hyperparameters Test Confusion Matrix*****\n",
      "Predicted Income    0     1\n",
      "Actual Income              \n",
      "0                 386   300\n",
      "1                  98  1901\n",
      "\n",
      "Grid Search Hyperparameters Test Accuracy = 85.1769%\n",
      "\n",
      "Compared to the random forest classifier created with default hyperparameters, the accuracy of the classifier created with optimal hyperparameters determined by grid search is 0.3970% better\n"
     ]
    }
   ],
   "source": [
    "# ************ Random Forest Classifier using grid search with best hyper-parameters ******************\n",
    "print(\"\\n************************************************************************\")\n",
    "print(\"*****Random Forest With Hyperparameters from Grid Search Train/Test*****\")\n",
    "print(\"************************************************************************\\n\")\n",
    "\n",
    "# Train the Classifier with new values from grid search\n",
    "rf_clf = RandomForestClassifier(max_depth = best_grid.best_params_[\"max_depth\"], \n",
    "\tmin_samples_split = best_grid.best_params_[\"min_samples_split\"], \n",
    "\tmin_samples_leaf = best_grid.best_params_[\"min_samples_leaf\"], \n",
    "\tbootstrap = best_grid.best_params_[\"bootstrap\"], \n",
    "\tmax_features = best_grid.best_params_[\"max_features\"], \n",
    "\tn_estimators = best_grid.best_params_[\"n_estimators\"], n_jobs=-1, random_state=0)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Perform predictions\n",
    "train_test_preds = rf_clf.predict(X_test)\n",
    "\n",
    "# View the first 5 predictions and the predicted probabilities \n",
    "print(\"\\n\")\n",
    "print(\"*****Grid Search Hyperparameters Test Predictions*****\")\n",
    "for i in range(0,5):\n",
    "\tprint(\"Prediction \" + str(i+1) + \" is \" + str(train_test_preds[i]) + \" with probabilities of \" + str(rf_clf.predict_proba(X_test)[i]))\n",
    "\n",
    "# Create confusion matrix\n",
    "print(\"\\n*****Grid Search Hyperparameters Test Confusion Matrix*****\")\n",
    "confusion_matrix = pd.crosstab(y_test, train_test_preds, rownames=['Actual Income'], colnames=['Predicted Income'])\n",
    "print(confusion_matrix)\n",
    "\n",
    "# Print accuracy\n",
    "grid_search_accuracy = (((confusion_matrix[0][0] + confusion_matrix[1][1])) / (X_test.shape[0]) * 100)\n",
    "print(\"\\nGrid Search Hyperparameters Test Accuracy = {0:0.4f}%\".format(grid_search_accuracy))\n",
    "\n",
    "print(\"\\nCompared to the random forest classifier created with default hyperparameters, the accuracy of the \" +\n",
    "\t\"classifier created with optimal hyperparameters determined by grid search is \" +\n",
    "\t\"{0:0.4f}% better\".format((grid_search_accuracy - default_accuracy)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
